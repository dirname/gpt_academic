import markdown
import importlib
import time
import inspect
import re
import os
import gradio
import shutil
import glob
from latex2mathml.converter import convert as tex2mathml
from functools import wraps, lru_cache
pj = os.path.join

"""
========================================================================
ç¬¬ä¸€éƒ¨åˆ†
å‡½æ•°æ’ä»¶è¾“å…¥è¾“å‡ºæ¥é©³åŒº
    - ChatBotWithCookies:   å¸¦Cookiesçš„Chatbotç±»ï¼Œä¸ºå®ç°æ›´å¤šå¼ºå¤§çš„åŠŸèƒ½åšåŸºç¡€
    - ArgsGeneralWrapper:   è£…é¥°å™¨å‡½æ•°ï¼Œç”¨äºé‡ç»„è¾“å…¥å‚æ•°ï¼Œæ”¹å˜è¾“å…¥å‚æ•°çš„é¡ºåºä¸ç»“æ„
    - update_ui:            åˆ·æ–°ç•Œé¢ç”¨ yield from update_ui(chatbot, history)
    - CatchException:       å°†æ’ä»¶ä¸­å‡ºçš„æ‰€æœ‰é—®é¢˜æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
    - HotReload:            å®ç°æ’ä»¶çš„çƒ­æ›´æ–°
    - trimmed_format_exc:   æ‰“å°tracebackï¼Œä¸ºäº†å®‰å…¨è€Œéšè—ç»å¯¹åœ°å€
========================================================================
"""

class ChatBotWithCookies(list):
    def __init__(self, cookie):
        """
        cookies = {
            'top_p': top_p,
            'temperature': temperature,
            'lock_plugin': bool,
            "files_to_promote": ["file1", "file2"],
            "most_recent_uploaded": {
                "path": "uploaded_path",
                "time": time.time(),
                "time_str": "timestr",
            }
        }
        """
        self._cookies = cookie

    def write_list(self, list):
        for t in list:
            self.append(t)

    def get_list(self):
        return [t for t in self]

    def get_cookies(self):
        return self._cookies


def ArgsGeneralWrapper(f):
    """
    è£…é¥°å™¨å‡½æ•°ï¼Œç”¨äºé‡ç»„è¾“å…¥å‚æ•°ï¼Œæ”¹å˜è¾“å…¥å‚æ•°çš„é¡ºåºä¸ç»“æ„ã€‚
    """
    def decorated(request: gradio.Request, cookies, max_length, llm_model, txt, txt2, top_p, temperature, chatbot, history, system_prompt, plugin_advanced_arg, *args):
        txt_passon = txt
        if txt == "" and txt2 != "": txt_passon = txt2
        # å¼•å…¥ä¸€ä¸ªæœ‰cookieçš„chatbot
        cookies.update({
            'top_p':top_p,
            'api_key': cookies['api_key'],
            'llm_model': llm_model,
            'temperature':temperature,
        })
        llm_kwargs = {
            'api_key': cookies['api_key'],
            'llm_model': llm_model,
            'top_p':top_p,
            'max_length': max_length,
            'temperature':temperature,
            'client_ip': request.client.host,
        }
        plugin_kwargs = {
            "advanced_arg": plugin_advanced_arg,
        }
        chatbot_with_cookie = ChatBotWithCookies(cookies)
        chatbot_with_cookie.write_list(chatbot)
        
        if cookies.get('lock_plugin', None) is None:
            # æ­£å¸¸çŠ¶æ€
            if len(args) == 0:  # æ’ä»¶é€šé“
                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)
            else:               # å¯¹è¯é€šé“ï¼Œæˆ–è€…åŸºç¡€åŠŸèƒ½é€šé“
                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, *args)
        else:
            # å¤„ç†å°‘æ•°æƒ…å†µä¸‹çš„ç‰¹æ®Šæ’ä»¶çš„é”å®šçŠ¶æ€
            module, fn_name = cookies['lock_plugin'].split('->')
            f_hot_reload = getattr(importlib.import_module(module, fn_name), fn_name)
            yield from f_hot_reload(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)
            # åˆ¤æ–­ä¸€ä¸‹ç”¨æˆ·æ˜¯å¦é”™è¯¯åœ°é€šè¿‡å¯¹è¯é€šé“è¿›å…¥ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è¿›è¡Œæé†’
            final_cookies = chatbot_with_cookie.get_cookies()
            # len(args) != 0 ä»£è¡¨â€œæäº¤â€é”®å¯¹è¯é€šé“ï¼Œæˆ–è€…åŸºç¡€åŠŸèƒ½é€šé“
            if len(args) != 0 and 'files_to_promote' in final_cookies and len(final_cookies['files_to_promote']) > 0:
                chatbot_with_cookie.append(["æ£€æµ‹åˆ°**æ»ç•™çš„ç¼“å­˜æ–‡æ¡£**ï¼Œè¯·åŠæ—¶å¤„ç†ã€‚", "è¯·åŠæ—¶ç‚¹å‡»â€œ**ä¿å­˜å½“å‰å¯¹è¯**â€è·å–æ‰€æœ‰æ»ç•™æ–‡æ¡£ã€‚"])
                yield from update_ui(chatbot_with_cookie, final_cookies['history'], msg="æ£€æµ‹åˆ°è¢«æ»ç•™çš„ç¼“å­˜æ–‡æ¡£")
    return decorated


def update_ui(chatbot, history, msg='æ­£å¸¸', **kwargs):  # åˆ·æ–°ç•Œé¢
    """
    åˆ·æ–°ç”¨æˆ·ç•Œé¢
    """
    assert isinstance(chatbot, ChatBotWithCookies), "åœ¨ä¼ é€’chatbotçš„è¿‡ç¨‹ä¸­ä¸è¦å°†å…¶ä¸¢å¼ƒã€‚å¿…è¦æ—¶, å¯ç”¨clearå°†å…¶æ¸…ç©º, ç„¶åç”¨for+appendå¾ªç¯é‡æ–°èµ‹å€¼ã€‚"
    cookies = chatbot.get_cookies()
    # å¤‡ä»½ä¸€ä»½Historyä½œä¸ºè®°å½•
    cookies.update({'history': history})
    # è§£å†³æ’ä»¶é”å®šæ—¶çš„ç•Œé¢æ˜¾ç¤ºé—®é¢˜
    if cookies.get('lock_plugin', None):
        label = cookies.get('llm_model', "") + " | " + "æ­£åœ¨é”å®šæ’ä»¶" + cookies.get('lock_plugin', None)
        chatbot_gr = gradio.update(value=chatbot, label=label)
        if cookies.get('label', "") != label: cookies['label'] = label   # è®°ä½å½“å‰çš„label
    elif cookies.get('label', None):
        chatbot_gr = gradio.update(value=chatbot, label=cookies.get('llm_model', ""))
        cookies['label'] = None    # æ¸…ç©ºlabel
    else:
        chatbot_gr = chatbot

    yield cookies, chatbot_gr, history, msg

def update_ui_lastest_msg(lastmsg, chatbot, history, delay=1):  # åˆ·æ–°ç•Œé¢
    """
    åˆ·æ–°ç”¨æˆ·ç•Œé¢
    """
    if len(chatbot) == 0: chatbot.append(["update_ui_last_msg", lastmsg])
    chatbot[-1] = list(chatbot[-1])
    chatbot[-1][-1] = lastmsg
    yield from update_ui(chatbot=chatbot, history=history)
    time.sleep(delay)


def trimmed_format_exc():
    import os, traceback
    str = traceback.format_exc()
    current_path = os.getcwd()
    replace_path = "."
    return str.replace(current_path, replace_path)

def CatchException(f):
    """
    è£…é¥°å™¨å‡½æ•°ï¼Œæ•æ‰å‡½æ•°fä¸­çš„å¼‚å¸¸å¹¶å°è£…åˆ°ä¸€ä¸ªç”Ÿæˆå™¨ä¸­è¿”å›ï¼Œå¹¶æ˜¾ç¤ºåˆ°èŠå¤©å½“ä¸­ã€‚
    """

    @wraps(f)
    def decorated(main_input, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, *args, **kwargs):
        try:
            yield from f(main_input, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, *args, **kwargs)
        except Exception as e:
            from check_proxy import check_proxy
            from toolbox import get_conf
            proxies, = get_conf('proxies')
            tb_str = '```\n' + trimmed_format_exc() + '```'
            if len(chatbot_with_cookie) == 0:
                chatbot_with_cookie.clear()
                chatbot_with_cookie.append(["æ’ä»¶è°ƒåº¦å¼‚å¸¸", "å¼‚å¸¸åŸå› "])
            chatbot_with_cookie[-1] = (chatbot_with_cookie[-1][0],
                           f"[Local Message] å®éªŒæ€§å‡½æ•°è°ƒç”¨å‡ºé”™: \n\n{tb_str} \n\nå½“å‰ä»£ç†å¯ç”¨æ€§: \n\n{check_proxy(proxies)}")
            yield from update_ui(chatbot=chatbot_with_cookie, history=history, msg=f'å¼‚å¸¸ {e}') # åˆ·æ–°ç•Œé¢
    return decorated


def HotReload(f):
    """
    HotReloadçš„è£…é¥°å™¨å‡½æ•°ï¼Œç”¨äºå®ç°Pythonå‡½æ•°æ’ä»¶çš„çƒ­æ›´æ–°ã€‚
    å‡½æ•°çƒ­æ›´æ–°æ˜¯æŒ‡åœ¨ä¸åœæ­¢ç¨‹åºè¿è¡Œçš„æƒ…å†µä¸‹ï¼Œæ›´æ–°å‡½æ•°ä»£ç ï¼Œä»è€Œè¾¾åˆ°å®æ—¶æ›´æ–°åŠŸèƒ½ã€‚
    åœ¨è£…é¥°å™¨å†…éƒ¨ï¼Œä½¿ç”¨wraps(f)æ¥ä¿ç•™å‡½æ•°çš„å…ƒä¿¡æ¯ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªåä¸ºdecoratedçš„å†…éƒ¨å‡½æ•°ã€‚
    å†…éƒ¨å‡½æ•°é€šè¿‡ä½¿ç”¨importlibæ¨¡å—çš„reloadå‡½æ•°å’Œinspectæ¨¡å—çš„getmoduleå‡½æ•°æ¥é‡æ–°åŠ è½½å¹¶è·å–å‡½æ•°æ¨¡å—ï¼Œ
    ç„¶åé€šè¿‡getattrå‡½æ•°è·å–å‡½æ•°åï¼Œå¹¶åœ¨æ–°æ¨¡å—ä¸­é‡æ–°åŠ è½½å‡½æ•°ã€‚
    æœ€åï¼Œä½¿ç”¨yield fromè¯­å¥è¿”å›é‡æ–°åŠ è½½è¿‡çš„å‡½æ•°ï¼Œå¹¶åœ¨è¢«è£…é¥°çš„å‡½æ•°ä¸Šæ‰§è¡Œã€‚
    æœ€ç»ˆï¼Œè£…é¥°å™¨å‡½æ•°è¿”å›å†…éƒ¨å‡½æ•°ã€‚è¿™ä¸ªå†…éƒ¨å‡½æ•°å¯ä»¥å°†å‡½æ•°çš„åŸå§‹å®šä¹‰æ›´æ–°ä¸ºæœ€æ–°ç‰ˆæœ¬ï¼Œå¹¶æ‰§è¡Œå‡½æ•°çš„æ–°ç‰ˆæœ¬ã€‚
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        fn_name = f.__name__
        f_hot_reload = getattr(importlib.reload(inspect.getmodule(f)), fn_name)
        yield from f_hot_reload(*args, **kwargs)
    return decorated


"""
========================================================================
ç¬¬äºŒéƒ¨åˆ†
å…¶ä»–å°å·¥å…·:
    - write_history_to_file:    å°†ç»“æœå†™å…¥markdownæ–‡ä»¶ä¸­
    - regular_txt_to_markdown:  å°†æ™®é€šæ–‡æœ¬è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„æ–‡æœ¬ã€‚
    - report_execption:         å‘chatbotä¸­æ·»åŠ ç®€å•çš„æ„å¤–é”™è¯¯ä¿¡æ¯
    - text_divide_paragraph:    å°†æ–‡æœ¬æŒ‰ç…§æ®µè½åˆ†éš”ç¬¦åˆ†å‰²å¼€ï¼Œç”Ÿæˆå¸¦æœ‰æ®µè½æ ‡ç­¾çš„HTMLä»£ç ã€‚
    - markdown_convertion:      ç”¨å¤šç§æ–¹å¼ç»„åˆï¼Œå°†markdownè½¬åŒ–ä¸ºå¥½çœ‹çš„html
    - format_io:                æ¥ç®¡gradioé»˜è®¤çš„markdownå¤„ç†æ–¹å¼
    - on_file_uploaded:         å¤„ç†æ–‡ä»¶çš„ä¸Šä¼ ï¼ˆè‡ªåŠ¨è§£å‹ï¼‰
    - on_report_generated:      å°†ç”Ÿæˆçš„æŠ¥å‘Šè‡ªåŠ¨æŠ•å°„åˆ°æ–‡ä»¶ä¸Šä¼ åŒº
    - clip_history:             å½“å†å²ä¸Šä¸‹æ–‡è¿‡é•¿æ—¶ï¼Œè‡ªåŠ¨æˆªæ–­
    - get_conf:                 è·å–è®¾ç½®
    - select_api_key:           æ ¹æ®å½“å‰çš„æ¨¡å‹ç±»åˆ«ï¼ŒæŠ½å–å¯ç”¨çš„api-key
========================================================================
"""

def get_reduce_token_percent(text):
    """
        * æ­¤å‡½æ•°æœªæ¥å°†è¢«å¼ƒç”¨
    """
    try:
        # text = "maximum context length is 4097 tokens. However, your messages resulted in 4870 tokens"
        pattern = r"(\d+)\s+tokens\b"
        match = re.findall(pattern, text)
        EXCEED_ALLO = 500  # ç¨å¾®ç•™ä¸€ç‚¹ä½™åœ°ï¼Œå¦åˆ™åœ¨å›å¤æ—¶ä¼šå› ä½™é‡å¤ªå°‘å‡ºé—®é¢˜
        max_limit = float(match[0]) - EXCEED_ALLO
        current_tokens = float(match[1])
        ratio = max_limit/current_tokens
        assert ratio > 0 and ratio < 1
        return ratio, str(int(current_tokens-max_limit))
    except:
        return 0.5, 'ä¸è¯¦'


def write_history_to_file(history, file_basename=None, file_fullname=None, auto_caption=True):
    """
    å°†å¯¹è¯è®°å½•historyä»¥Markdownæ ¼å¼å†™å…¥æ–‡ä»¶ä¸­ã€‚å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œåˆ™ä½¿ç”¨å½“å‰æ—¶é—´ç”Ÿæˆæ–‡ä»¶åã€‚
    """
    import os
    import time
    if file_fullname is None:
        if file_basename is not None:
            file_fullname = pj(get_log_folder(), file_basename)
        else:
            file_fullname = pj(get_log_folder(), f'GPT-Academic-{gen_time_str()}.md')
    os.makedirs(os.path.dirname(file_fullname), exist_ok=True)
    with open(file_fullname, 'w', encoding='utf8') as f:
        f.write('# GPT-Academic Report\n')
        for i, content in enumerate(history):
            try:    
                if type(content) != str: content = str(content)
            except:
                continue
            if i % 2 == 0 and auto_caption:
                f.write('## ')
            try:
                f.write(content)
            except:
                # remove everything that cannot be handled by utf8
                f.write(content.encode('utf-8', 'ignore').decode())
            f.write('\n\n')
    res = os.path.abspath(file_fullname)
    return res


def regular_txt_to_markdown(text):
    """
    å°†æ™®é€šæ–‡æœ¬è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„æ–‡æœ¬ã€‚
    """
    text = text.replace('\n', '\n\n')
    text = text.replace('\n\n\n', '\n\n')
    text = text.replace('\n\n\n', '\n\n')
    return text




def report_execption(chatbot, history, a, b):
    """
    å‘chatbotä¸­æ·»åŠ é”™è¯¯ä¿¡æ¯
    """
    chatbot.append((a, b))
    history.extend([a, b])


def text_divide_paragraph(text):
    """
    å°†æ–‡æœ¬æŒ‰ç…§æ®µè½åˆ†éš”ç¬¦åˆ†å‰²å¼€ï¼Œç”Ÿæˆå¸¦æœ‰æ®µè½æ ‡ç­¾çš„HTMLä»£ç ã€‚
    """
    pre = '<div class="markdown-body">'
    suf = '</div>'
    if text.startswith(pre) and text.endswith(suf):
        return text
    
    if '```' in text:
        # careful input
        return pre + text + suf
    else:
        # wtf input
        lines = text.split("\n")
        for i, line in enumerate(lines):
            lines[i] = lines[i].replace(" ", "&nbsp;")
        text = "</br>".join(lines)
        return pre + text + suf


@lru_cache(maxsize=128) # ä½¿ç”¨ lruç¼“å­˜ åŠ å¿«è½¬æ¢é€Ÿåº¦
def markdown_convertion(txt):
    """
    å°†Markdownæ ¼å¼çš„æ–‡æœ¬è½¬æ¢ä¸ºHTMLæ ¼å¼ã€‚å¦‚æœåŒ…å«æ•°å­¦å…¬å¼ï¼Œåˆ™å…ˆå°†å…¬å¼è½¬æ¢ä¸ºHTMLæ ¼å¼ã€‚
    """
    pre = '<div class="markdown-body">'
    suf = '</div>'
    if txt.startswith(pre) and txt.endswith(suf):
        # print('è­¦å‘Šï¼Œè¾“å…¥äº†å·²ç»ç»è¿‡è½¬åŒ–çš„å­—ç¬¦ä¸²ï¼ŒäºŒæ¬¡è½¬åŒ–å¯èƒ½å‡ºé—®é¢˜')
        return txt # å·²ç»è¢«è½¬åŒ–è¿‡ï¼Œä¸éœ€è¦å†æ¬¡è½¬åŒ–
    
    markdown_extension_configs = {
        'mdx_math': {
            'enable_dollar_delimiter': True,
            'use_gitlab_delimiters': False,
        },
    }
    find_equation_pattern = r'<script type="math/tex(?:.*?)>(.*?)</script>'

    def tex2mathml_catch_exception(content, *args, **kwargs):
        try:
            content = tex2mathml(content, *args, **kwargs)
        except:
            content = content
        return content

    def replace_math_no_render(match):
        content = match.group(1)
        if 'mode=display' in match.group(0):
            content = content.replace('\n', '</br>')
            return f"<font color=\"#00FF00\">$$</font><font color=\"#FF00FF\">{content}</font><font color=\"#00FF00\">$$</font>"
        else:
            return f"<font color=\"#00FF00\">$</font><font color=\"#FF00FF\">{content}</font><font color=\"#00FF00\">$</font>"

    def replace_math_render(match):
        content = match.group(1)
        if 'mode=display' in match.group(0):
            if '\\begin{aligned}' in content:
                content = content.replace('\\begin{aligned}', '\\begin{array}')
                content = content.replace('\\end{aligned}', '\\end{array}')
                content = content.replace('&', ' ')
            content = tex2mathml_catch_exception(content, display="block")
            return content
        else:
            return tex2mathml_catch_exception(content)

    def markdown_bug_hunt(content):
        """
        è§£å†³ä¸€ä¸ªmdx_mathçš„bugï¼ˆå•$åŒ…è£¹beginå‘½ä»¤æ—¶å¤šä½™<script>ï¼‰
        """
        content = content.replace('<script type="math/tex">\n<script type="math/tex; mode=display">', '<script type="math/tex; mode=display">')
        content = content.replace('</script>\n</script>', '</script>')
        return content

    def is_equation(txt):
        """
        åˆ¤å®šæ˜¯å¦ä¸ºå…¬å¼ | æµ‹è¯•1 å†™å‡ºæ´›ä¼¦å…¹å®šå¾‹ï¼Œä½¿ç”¨texæ ¼å¼å…¬å¼ æµ‹è¯•2 ç»™å‡ºæŸ¯è¥¿ä¸ç­‰å¼ï¼Œä½¿ç”¨latexæ ¼å¼ æµ‹è¯•3 å†™å‡ºéº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„
        """
        if '```' in txt and '```reference' not in txt: return False
        if '$' not in txt and '\\[' not in txt: return False
        mathpatterns = {
            r'(?<!\\|\$)(\$)([^\$]+)(\$)': {'allow_multi_lines': False},                            # Â $...$
            r'(?<!\\)(\$\$)([^\$]+)(\$\$)': {'allow_multi_lines': True},                            # $$...$$
            r'(?<!\\)(\\\[)(.+?)(\\\])': {'allow_multi_lines': False},                              # \[...\]
            # r'(?<!\\)(\\\()(.+?)(\\\))': {'allow_multi_lines': False},                            # \(...\)
            # r'(?<!\\)(\\begin{([a-z]+?\*?)})(.+?)(\\end{\2})': {'allow_multi_lines': True},       # \begin...\end
            # r'(?<!\\)(\$`)([^`]+)(`\$)': {'allow_multi_lines': False},                            # $`...`$
        }
        matches = []
        for pattern, property in mathpatterns.items():
            flags = re.ASCII|re.DOTALL if property['allow_multi_lines'] else re.ASCII
            matches.extend(re.findall(pattern, txt, flags))
        if len(matches) == 0: return False
        contain_any_eq = False
        illegal_pattern = re.compile(r'[^\x00-\x7F]|echo')
        for match in matches:
            if len(match) != 3: return False
            eq_canidate = match[1]
            if illegal_pattern.search(eq_canidate): 
                return False
            else: 
                contain_any_eq = True
        return contain_any_eq

    if is_equation(txt):  # æœ‰$æ ‡è¯†çš„å…¬å¼ç¬¦å·ï¼Œä¸”æ²¡æœ‰ä»£ç æ®µ```çš„æ ‡è¯†
        # convert everything to html format
        split = markdown.markdown(text='---')
        convert_stage_1 = markdown.markdown(text=txt, extensions=['sane_lists', 'tables', 'mdx_math', 'fenced_code'], extension_configs=markdown_extension_configs)
        convert_stage_1 = markdown_bug_hunt(convert_stage_1)
        # 1. convert to easy-to-copy tex (do not render math)
        convert_stage_2_1, n = re.subn(find_equation_pattern, replace_math_no_render, convert_stage_1, flags=re.DOTALL)
        # 2. convert to rendered equation
        convert_stage_2_2, n = re.subn(find_equation_pattern, replace_math_render, convert_stage_1, flags=re.DOTALL)
        # cat them together
        return pre + convert_stage_2_1 + f'{split}' + convert_stage_2_2 + suf
    else:
        return pre + markdown.markdown(txt, extensions=['sane_lists', 'tables', 'fenced_code', 'codehilite']) + suf


def close_up_code_segment_during_stream(gpt_reply):
    """
    åœ¨gptè¾“å‡ºä»£ç çš„ä¸­é€”ï¼ˆè¾“å‡ºäº†å‰é¢çš„```ï¼Œä½†è¿˜æ²¡è¾“å‡ºå®Œåé¢çš„```ï¼‰ï¼Œè¡¥ä¸Šåé¢çš„```

    Args:
        gpt_reply (str): GPTæ¨¡å‹è¿”å›çš„å›å¤å­—ç¬¦ä¸²ã€‚

    Returns:
        str: è¿”å›ä¸€ä¸ªæ–°çš„å­—ç¬¦ä¸²ï¼Œå°†è¾“å‡ºä»£ç ç‰‡æ®µçš„â€œåé¢çš„```â€è¡¥ä¸Šã€‚

    """
    if '```' not in gpt_reply:
        return gpt_reply
    if gpt_reply.endswith('```'):
        return gpt_reply

    # æ’é™¤äº†ä»¥ä¸Šä¸¤ä¸ªæƒ…å†µï¼Œæˆ‘ä»¬
    segments = gpt_reply.split('```')
    n_mark = len(segments) - 1
    if n_mark % 2 == 1:
        # print('è¾“å‡ºä»£ç ç‰‡æ®µä¸­ï¼')
        return gpt_reply+'\n```'
    else:
        return gpt_reply


def format_io(self, y):
    """
    å°†è¾“å…¥å’Œè¾“å‡ºè§£æä¸ºHTMLæ ¼å¼ã€‚å°†yä¸­æœ€åä¸€é¡¹çš„è¾“å…¥éƒ¨åˆ†æ®µè½åŒ–ï¼Œå¹¶å°†è¾“å‡ºéƒ¨åˆ†çš„Markdownå’Œæ•°å­¦å…¬å¼è½¬æ¢ä¸ºHTMLæ ¼å¼ã€‚
    """
    if y is None or y == []:
        return []
    i_ask, gpt_reply = y[-1]
    # è¾“å…¥éƒ¨åˆ†å¤ªè‡ªç”±ï¼Œé¢„å¤„ç†ä¸€æ³¢
    if i_ask is not None: i_ask = text_divide_paragraph(i_ask)
    # å½“ä»£ç è¾“å‡ºåŠæˆªçš„æ—¶å€™ï¼Œè¯•ç€è¡¥ä¸Šåä¸ª```
    if gpt_reply is not None: gpt_reply = close_up_code_segment_during_stream(gpt_reply)
    # process
    y[-1] = (
        None if i_ask is None else markdown.markdown(i_ask, extensions=['fenced_code', 'tables']),
        None if gpt_reply is None else markdown_convertion(gpt_reply)
    )
    return y


def find_free_port():
    """
    è¿”å›å½“å‰ç³»ç»Ÿä¸­å¯ç”¨çš„æœªä½¿ç”¨ç«¯å£ã€‚
    """
    import socket
    from contextlib import closing
    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
        s.bind(('', 0))
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        return s.getsockname()[1]


def extract_archive(file_path, dest_dir):
    import zipfile
    import tarfile
    import os
    # Get the file extension of the input file
    file_extension = os.path.splitext(file_path)[1]

    # Extract the archive based on its extension
    if file_extension == '.zip':
        with zipfile.ZipFile(file_path, 'r') as zipobj:
            zipobj.extractall(path=dest_dir)
            print("Successfully extracted zip archive to {}".format(dest_dir))

    elif file_extension in ['.tar', '.gz', '.bz2']:
        with tarfile.open(file_path, 'r:*') as tarobj:
            tarobj.extractall(path=dest_dir)
            print("Successfully extracted tar archive to {}".format(dest_dir))

    # ç¬¬ä¸‰æ–¹åº“ï¼Œéœ€è¦é¢„å…ˆpip install rarfile
    # æ­¤å¤–ï¼ŒWindowsä¸Šè¿˜éœ€è¦å®‰è£…winrarè½¯ä»¶ï¼Œé…ç½®å…¶Pathç¯å¢ƒå˜é‡ï¼Œå¦‚"C:\Program Files\WinRAR"æ‰å¯ä»¥
    elif file_extension == '.rar':
        try:
            import rarfile
            with rarfile.RarFile(file_path) as rf:
                rf.extractall(path=dest_dir)
                print("Successfully extracted rar archive to {}".format(dest_dir))
        except:
            print("Rar format requires additional dependencies to install")
            return '\n\nè§£å‹å¤±è´¥! éœ€è¦å®‰è£…pip install rarfileæ¥è§£å‹raræ–‡ä»¶ã€‚å»ºè®®ï¼šä½¿ç”¨zipå‹ç¼©æ ¼å¼ã€‚'

    # ç¬¬ä¸‰æ–¹åº“ï¼Œéœ€è¦é¢„å…ˆpip install py7zr
    elif file_extension == '.7z':
        try:
            import py7zr
            with py7zr.SevenZipFile(file_path, mode='r') as f:
                f.extractall(path=dest_dir)
                print("Successfully extracted 7z archive to {}".format(dest_dir))
        except:
            print("7z format requires additional dependencies to install")
            return '\n\nè§£å‹å¤±è´¥! éœ€è¦å®‰è£…pip install py7zræ¥è§£å‹7zæ–‡ä»¶'
    else:
        return ''
    return ''


def find_recent_files(directory):
    """
        me: find files that is created with in one minutes under a directory with python, write a function
        gpt: here it is!
    """
    import os
    import time
    current_time = time.time()
    one_minute_ago = current_time - 60
    recent_files = []
    if not os.path.exists(directory): 
        os.makedirs(directory, exist_ok=True)
    for filename in os.listdir(directory):
        file_path = pj(directory, filename)
        if file_path.endswith('.log'):
            continue
        created_time = os.path.getmtime(file_path)
        if created_time >= one_minute_ago:
            if os.path.isdir(file_path):
                continue
            recent_files.append(file_path)

    return recent_files

def promote_file_to_downloadzone(file, rename_file=None, chatbot=None):
    # å°†æ–‡ä»¶å¤åˆ¶ä¸€ä»½åˆ°ä¸‹è½½åŒº
    import shutil
    if rename_file is None: rename_file = f'{gen_time_str()}-{os.path.basename(file)}'
    new_path = pj(get_log_folder(), rename_file)
    # å¦‚æœå·²ç»å­˜åœ¨ï¼Œå…ˆåˆ é™¤
    if os.path.exists(new_path) and not os.path.samefile(new_path, file): os.remove(new_path)
    # æŠŠæ–‡ä»¶å¤åˆ¶è¿‡å»
    if not os.path.exists(new_path): shutil.copyfile(file, new_path)
    # å°†æ–‡ä»¶æ·»åŠ åˆ°chatbot cookieä¸­ï¼Œé¿å…å¤šç”¨æˆ·å¹²æ‰°
    if chatbot is not None:
        if 'files_to_promote' in chatbot._cookies: current = chatbot._cookies['files_to_promote']
        else: current = []
        chatbot._cookies.update({'files_to_promote': [new_path] + current})
    return new_path

def disable_auto_promotion(chatbot):
    chatbot._cookies.update({'files_to_promote': []})
    return

def is_the_upload_folder(string):
    PATH_PRIVATE_UPLOAD, = get_conf('PATH_PRIVATE_UPLOAD')
    pattern = r'^PATH_PRIVATE_UPLOAD/[A-Za-z0-9_-]+/\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2}$'
    pattern = pattern.replace('PATH_PRIVATE_UPLOAD', PATH_PRIVATE_UPLOAD)
    if re.match(pattern, string): return True
    else: return False

def del_outdated_uploads(outdate_time_seconds):
    PATH_PRIVATE_UPLOAD, = get_conf('PATH_PRIVATE_UPLOAD')
    current_time = time.time()
    one_hour_ago = current_time - outdate_time_seconds
    # Get a list of all subdirectories in the PATH_PRIVATE_UPLOAD folder
    # Remove subdirectories that are older than one hour
    for subdirectory in glob.glob(f'{PATH_PRIVATE_UPLOAD}/*/*'):
        subdirectory_time = os.path.getmtime(subdirectory)
        if subdirectory_time < one_hour_ago:
            try: shutil.rmtree(subdirectory)
            except: pass
    return

def on_file_uploaded(request: gradio.Request, files, chatbot, txt, txt2, checkboxes, cookies):
    """
    å½“æ–‡ä»¶è¢«ä¸Šä¼ æ—¶çš„å›è°ƒå‡½æ•°
    """
    if len(files) == 0:
        return chatbot, txt
    
    # ç§»é™¤è¿‡æ—¶çš„æ—§æ–‡ä»¶ä»è€ŒèŠ‚çœç©ºé—´&ä¿æŠ¤éšç§
    outdate_time_seconds = 60
    del_outdated_uploads(outdate_time_seconds)

    # åˆ›å»ºå·¥ä½œè·¯å¾„
    user_name = "default" if not request.username else request.username
    time_tag = gen_time_str()
    PATH_PRIVATE_UPLOAD, = get_conf('PATH_PRIVATE_UPLOAD')
    target_path_base = pj(PATH_PRIVATE_UPLOAD, user_name, time_tag)
    os.makedirs(target_path_base, exist_ok=True)

    # é€ä¸ªæ–‡ä»¶è½¬ç§»åˆ°ç›®æ ‡è·¯å¾„
    upload_msg = ''
    for file in files:
        file_origin_name = os.path.basename(file.orig_name)
        this_file_path = pj(target_path_base, file_origin_name)
        shutil.move(file.name, this_file_path)
        upload_msg += extract_archive(file_path=this_file_path, dest_dir=this_file_path+'.extract')
    
    # æ•´ç†æ–‡ä»¶é›†åˆ
    moved_files = [fp for fp in glob.glob(f'{target_path_base}/**/*', recursive=True)]
    if "æµ®åŠ¨è¾“å…¥åŒº" in checkboxes: 
        txt, txt2 = "", target_path_base
    else:
        txt, txt2 = target_path_base, ""

    # è¾“å‡ºæ¶ˆæ¯
    moved_files_str = '\t\n\n'.join(moved_files)
    chatbot.append(['æˆ‘ä¸Šä¼ äº†æ–‡ä»¶ï¼Œè¯·æŸ¥æ”¶', 
                    f'[Local Message] æ”¶åˆ°ä»¥ä¸‹æ–‡ä»¶: \n\n{moved_files_str}' +
                    f'\n\nè°ƒç”¨è·¯å¾„å‚æ•°å·²è‡ªåŠ¨ä¿®æ­£åˆ°: \n\n{txt}' +
                    f'\n\nç°åœ¨æ‚¨ç‚¹å‡»ä»»æ„å‡½æ•°æ’ä»¶æ—¶ï¼Œä»¥ä¸Šæ–‡ä»¶å°†è¢«ä½œä¸ºè¾“å…¥å‚æ•°'+upload_msg])
    
    # è®°å½•è¿‘æœŸæ–‡ä»¶
    cookies.update({
        'most_recent_uploaded': {
            'path': target_path_base,
            'time': time.time(),
            'time_str': time_tag
    }})
    return chatbot, txt, txt2, cookies


def on_report_generated(cookies, files, chatbot):
    from toolbox import find_recent_files
    PATH_LOGGING, = get_conf('PATH_LOGGING')
    if 'files_to_promote' in cookies:
        report_files = cookies['files_to_promote']
        cookies.pop('files_to_promote')
    else:
        report_files = find_recent_files(PATH_LOGGING)
    if len(report_files) == 0:
        return cookies, None, chatbot
    # files.extend(report_files)
    file_links = ''
    for f in report_files: file_links += f'<br/><a href="file={os.path.abspath(f)}" target="_blank">{f}</a>'
    chatbot.append(['æŠ¥å‘Šå¦‚ä½•è¿œç¨‹è·å–ï¼Ÿ', f'æŠ¥å‘Šå·²ç»æ·»åŠ åˆ°å³ä¾§â€œæ–‡ä»¶ä¸Šä¼ åŒºâ€ï¼ˆå¯èƒ½å¤„äºæŠ˜å çŠ¶æ€ï¼‰ï¼Œè¯·æŸ¥æ”¶ã€‚{file_links}'])
    return cookies, report_files, chatbot

def load_chat_cookies():
    API_KEY, LLM_MODEL, AZURE_API_KEY = get_conf('API_KEY', 'LLM_MODEL', 'AZURE_API_KEY')
    if is_any_api_key(AZURE_API_KEY):
        if is_any_api_key(API_KEY): API_KEY = API_KEY + ',' + AZURE_API_KEY
        else: API_KEY = AZURE_API_KEY
    return {'api_key': API_KEY, 'llm_model': LLM_MODEL}

def is_openai_api_key(key):
    CUSTOM_API_KEY_PATTERN, = get_conf('CUSTOM_API_KEY_PATTERN')
    if len(CUSTOM_API_KEY_PATTERN) != 0:
        API_MATCH_ORIGINAL = re.match(CUSTOM_API_KEY_PATTERN, key)
    else:
        API_MATCH_ORIGINAL = re.match(r"sk-[a-zA-Z0-9]{48}$", key)
    return bool(API_MATCH_ORIGINAL)

def is_azure_api_key(key):
    API_MATCH_AZURE = re.match(r"[a-zA-Z0-9]{32}$", key)
    return bool(API_MATCH_AZURE)

def is_api2d_key(key):
    API_MATCH_API2D = re.match(r"fk[a-zA-Z0-9]{6}-[a-zA-Z0-9]{32}$", key)
    return bool(API_MATCH_API2D)

def is_any_api_key(key):
    if ',' in key:
        keys = key.split(',')
        for k in keys:
            if is_any_api_key(k): return True
        return False
    else:
        return is_openai_api_key(key) or is_api2d_key(key) or is_azure_api_key(key)

def what_keys(keys):
    avail_key_list = {'OpenAI Key':0, "Azure Key":0, "API2D Key":0}
    key_list = keys.split(',')

    for k in key_list:
        if is_openai_api_key(k): 
            avail_key_list['OpenAI Key'] += 1

    for k in key_list:
        if is_api2d_key(k): 
            avail_key_list['API2D Key'] += 1

    for k in key_list:
        if is_azure_api_key(k): 
            avail_key_list['Azure Key'] += 1

    return f"æ£€æµ‹åˆ°ï¼š PuerHub AI ä»¤ç‰Œ {avail_key_list['OpenAI Key']} ä¸ª, Azure Key {avail_key_list['Azure Key']} ä¸ª, API2D Key {avail_key_list['API2D Key']} ä¸ª"

def select_api_key(keys, llm_model):
    import random
    avail_key_list = []
    key_list = keys.split(',')

    if llm_model.startswith('gpt-') or llm_model.startswith('claude-'):
        for k in key_list:
            if is_openai_api_key(k): avail_key_list.append(k)

    if llm_model.startswith('api2d-'):
        for k in key_list:
            if is_api2d_key(k): avail_key_list.append(k)

    if llm_model.startswith('azure-'):
        for k in key_list:
            if is_azure_api_key(k): avail_key_list.append(k)

    if len(avail_key_list) == 0:
        raise RuntimeError(f"æ‚¨æä¾›çš„ PuerHub AI ä»¤ç‰Œä¸æ»¡è¶³è¦æ±‚, æ— æ³•ä½¿ç”¨{llm_model}! è¿™å¯èƒ½æ˜¯ PuerHub AI ä¸æ”¯æŒè¯¥æ¨¡å‹æˆ–æ‚¨ä½¿ç”¨äº†é”™è¯¯çš„ PuerHub API ä»¤ç‰Œè¯·é‡æ–°åˆ° [ç‚¹å‡»è¿™é‡Œ](https://ai.puerhub.xyz/token) ç”Ÿæˆä»¤ç‰Œ ğŸ”‘")

    api_key = random.choice(avail_key_list) # éšæœºè´Ÿè½½å‡è¡¡
    return api_key

def read_env_variable(arg, default_value):
    """
    ç¯å¢ƒå˜é‡å¯ä»¥æ˜¯ `GPT_ACADEMIC_CONFIG`(ä¼˜å…ˆ)ï¼Œä¹Ÿå¯ä»¥ç›´æ¥æ˜¯`CONFIG`
    ä¾‹å¦‚åœ¨windows cmdä¸­ï¼Œæ—¢å¯ä»¥å†™ï¼š
        set USE_PROXY=True
        set API_KEY=sk-j7caBpkRoxxxxxxxxxxxxxxxxxxxxxxxxxxxx
        set proxies={"http":"http://127.0.0.1:10085", "https":"http://127.0.0.1:10085",}
        set AVAIL_LLM_MODELS=["gpt-3.5-turbo", "chatglm"]
        set AUTHENTICATION=[("username", "password"), ("username2", "password2")]
    ä¹Ÿå¯ä»¥å†™ï¼š
        set GPT_ACADEMIC_USE_PROXY=True
        set GPT_ACADEMIC_API_KEY=sk-j7caBpkRoxxxxxxxxxxxxxxxxxxxxxxxxxxxx
        set GPT_ACADEMIC_proxies={"http":"http://127.0.0.1:10085", "https":"http://127.0.0.1:10085",}
        set GPT_ACADEMIC_AVAIL_LLM_MODELS=["gpt-3.5-turbo", "chatglm"]
        set GPT_ACADEMIC_AUTHENTICATION=[("username", "password"), ("username2", "password2")]
    """
    from colorful import printäº®çº¢, printäº®ç»¿
    arg_with_prefix = "GPT_ACADEMIC_" + arg 
    if arg_with_prefix in os.environ: 
        env_arg = os.environ[arg_with_prefix]
    elif arg in os.environ: 
        env_arg = os.environ[arg]
    else:
        raise KeyError
    print(f"[ENV_VAR] å°è¯•åŠ è½½{arg}ï¼Œé»˜è®¤å€¼ï¼š{default_value} --> ä¿®æ­£å€¼ï¼š{env_arg}")
    try:
        if isinstance(default_value, bool):
            env_arg = env_arg.strip()
            if env_arg == 'True': r = True
            elif env_arg == 'False': r = False
            else: print('enter True or False, but have:', env_arg); r = default_value
        elif isinstance(default_value, int):
            r = int(env_arg)
        elif isinstance(default_value, float):
            r = float(env_arg)
        elif isinstance(default_value, str):
            r = env_arg.strip()
        elif isinstance(default_value, dict):
            r = eval(env_arg)
        elif isinstance(default_value, list):
            r = eval(env_arg)
        elif default_value is None:
            assert arg == "proxies"
            r = eval(env_arg)
        else:
            printäº®çº¢(f"[ENV_VAR] ç¯å¢ƒå˜é‡{arg}ä¸æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®! ")
            raise KeyError
    except:
        printäº®çº¢(f"[ENV_VAR] ç¯å¢ƒå˜é‡{arg}åŠ è½½å¤±è´¥! ")
        raise KeyError(f"[ENV_VAR] ç¯å¢ƒå˜é‡{arg}åŠ è½½å¤±è´¥! ")

    printäº®ç»¿(f"[ENV_VAR] æˆåŠŸè¯»å–ç¯å¢ƒå˜é‡{arg}")
    return r

@lru_cache(maxsize=128)
def read_single_conf_with_lru_cache(arg):
    from colorful import printäº®çº¢, printäº®ç»¿, printäº®è“
    try:
        # ä¼˜å…ˆçº§1. è·å–ç¯å¢ƒå˜é‡ä½œä¸ºé…ç½®
        default_ref = getattr(importlib.import_module('config'), arg)   # è¯»å–é»˜è®¤å€¼ä½œä¸ºæ•°æ®ç±»å‹è½¬æ¢çš„å‚è€ƒ
        r = read_env_variable(arg, default_ref) 
    except:
        try:
            # ä¼˜å…ˆçº§2. è·å–config_privateä¸­çš„é…ç½®
            r = getattr(importlib.import_module('config_private'), arg)
        except:
            # ä¼˜å…ˆçº§3. è·å–configä¸­çš„é…ç½®
            r = getattr(importlib.import_module('config'), arg)

    # åœ¨è¯»å–API_KEYæ—¶ï¼Œæ£€æŸ¥ä¸€ä¸‹æ˜¯ä¸æ˜¯å¿˜äº†æ”¹config
    if arg == 'API_KEY':
        printäº®è“(f"[API_KEY] æœ¬é¡¹ç›®ç°å·²æ”¯æŒOpenAIå’ŒAzureçš„api-keyã€‚ä¹Ÿæ”¯æŒåŒæ—¶å¡«å†™å¤šä¸ªapi-keyï¼Œå¦‚API_KEY=\"openai-key1,openai-key2,azure-key3\"")
        printäº®è“(f"[API_KEY] æ‚¨æ—¢å¯ä»¥åœ¨config.pyä¸­ä¿®æ”¹api-key(s)ï¼Œä¹Ÿå¯ä»¥åœ¨é—®é¢˜è¾“å…¥åŒºè¾“å…¥ä¸´æ—¶çš„api-key(s)ï¼Œç„¶åå›è½¦é”®æäº¤åå³å¯ç”Ÿæ•ˆã€‚")
        if is_any_api_key(r):
            printäº®ç»¿(f"[API_KEY] æ‚¨çš„ API_KEY æ˜¯: {r[:15]}*** API_KEY å¯¼å…¥æˆåŠŸ")
        else:
            printäº®çº¢( "[API_KEY] æ‚¨çš„ API_KEY ä¸æ»¡è¶³ä»»ä½•ä¸€ç§å·²çŸ¥çš„å¯†é’¥æ ¼å¼ï¼Œè¯·åœ¨configæ–‡ä»¶ä¸­ä¿®æ”¹APIå¯†é’¥ä¹‹åå†è¿è¡Œã€‚")
    if arg == 'proxies':
        if not read_single_conf_with_lru_cache('USE_PROXY'): r = None   # æ£€æŸ¥USE_PROXYï¼Œé˜²æ­¢proxieså•ç‹¬èµ·ä½œç”¨
        if r is None:
            printäº®çº¢('[PROXY] ç½‘ç»œä»£ç†çŠ¶æ€ï¼šæœªé…ç½®ã€‚æ— ä»£ç†çŠ¶æ€ä¸‹å¾ˆå¯èƒ½æ— æ³•è®¿é—®OpenAIå®¶æ—çš„æ¨¡å‹ã€‚å»ºè®®ï¼šæ£€æŸ¥USE_PROXYé€‰é¡¹æ˜¯å¦ä¿®æ”¹ã€‚')
        else:
            printäº®ç»¿('[PROXY] ç½‘ç»œä»£ç†çŠ¶æ€ï¼šå·²é…ç½®ã€‚é…ç½®ä¿¡æ¯å¦‚ä¸‹ï¼š', r)
            assert isinstance(r, dict), 'proxiesæ ¼å¼é”™è¯¯ï¼Œè¯·æ³¨æ„proxiesé€‰é¡¹çš„æ ¼å¼ï¼Œä¸è¦é—æ¼æ‹¬å·ã€‚'
    return r


@lru_cache(maxsize=128)
def get_conf(*args):
    # å»ºè®®æ‚¨å¤åˆ¶ä¸€ä¸ªconfig_private.pyæ”¾è‡ªå·±çš„ç§˜å¯†, å¦‚APIå’Œä»£ç†ç½‘å€, é¿å…ä¸å°å¿ƒä¼ githubè¢«åˆ«äººçœ‹åˆ°
    res = []
    for arg in args:
        r = read_single_conf_with_lru_cache(arg)
        res.append(r)
    return res


def clear_line_break(txt):
    txt = txt.replace('\n', ' ')
    txt = txt.replace('  ', ' ')
    txt = txt.replace('  ', ' ')
    return txt


class DummyWith():
    """
    è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºDummyWithçš„ç©ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œ
    å®ƒçš„ä½œç”¨æ˜¯â€¦â€¦é¢â€¦â€¦å°±æ˜¯ä¸èµ·ä½œç”¨ï¼Œå³åœ¨ä»£ç ç»“æ„ä¸å˜å¾—æƒ…å†µä¸‹å–ä»£å…¶ä»–çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ˜¯ä¸€ç§Pythonå¯¹è±¡ï¼Œç”¨äºä¸withè¯­å¥ä¸€èµ·ä½¿ç”¨ï¼Œ
    ä»¥ç¡®ä¿ä¸€äº›èµ„æºåœ¨ä»£ç å—æ‰§è¡ŒæœŸé—´å¾—åˆ°æ­£ç¡®çš„åˆå§‹åŒ–å’Œæ¸…ç†ã€‚
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¿…é¡»å®ç°ä¸¤ä¸ªæ–¹æ³•ï¼Œåˆ†åˆ«ä¸º __enter__()å’Œ __exit__()ã€‚
    åœ¨ä¸Šä¸‹æ–‡æ‰§è¡Œå¼€å§‹çš„æƒ…å†µä¸‹ï¼Œ__enter__()æ–¹æ³•ä¼šåœ¨ä»£ç å—è¢«æ‰§è¡Œå‰è¢«è°ƒç”¨ï¼Œ
    è€Œåœ¨ä¸Šä¸‹æ–‡æ‰§è¡Œç»“æŸæ—¶ï¼Œ__exit__()æ–¹æ³•åˆ™ä¼šè¢«è°ƒç”¨ã€‚
    """
    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        return

def run_gradio_in_subpath(demo, auth, port, custom_path):
    """
    æŠŠgradioçš„è¿è¡Œåœ°å€æ›´æ”¹åˆ°æŒ‡å®šçš„äºŒæ¬¡è·¯å¾„ä¸Š
    """
    def is_path_legal(path: str)->bool:
        '''
        check path for sub url
        path: path to check
        return value: do sub url wrap
        '''
        if path == "/": return True
        if len(path) == 0:
            print("ilegal custom path: {}\npath must not be empty\ndeploy on root url".format(path))
            return False
        if path[0] == '/':
            if path[1] != '/':
                print("deploy on sub-path {}".format(path))
                return True
            return False
        print("ilegal custom path: {}\npath should begin with \'/\'\ndeploy on root url".format(path))
        return False

    if not is_path_legal(custom_path): raise RuntimeError('Ilegal custom path')
    import uvicorn
    import gradio as gr
    from fastapi import FastAPI
    app = FastAPI()
    if custom_path != "/":
        @app.get("/")
        def read_main(): 
            return {"message": f"Gradio is running at: {custom_path}"}
    app = gr.mount_gradio_app(app, demo, path=custom_path)
    uvicorn.run(app, host="0.0.0.0", port=port) # , auth=auth


def clip_history(inputs, history, tokenizer, max_token_limit):
    """
    reduce the length of history by clipping.
    this function search for the longest entries to clip, little by little,
    until the number of token of history is reduced under threshold.
    é€šè¿‡è£å‰ªæ¥ç¼©çŸ­å†å²è®°å½•çš„é•¿åº¦ã€‚ 
    æ­¤å‡½æ•°é€æ¸åœ°æœç´¢æœ€é•¿çš„æ¡ç›®è¿›è¡Œå‰ªè¾‘ï¼Œ
    ç›´åˆ°å†å²è®°å½•çš„æ ‡è®°æ•°é‡é™ä½åˆ°é˜ˆå€¼ä»¥ä¸‹ã€‚
    """
    import numpy as np
    from request_llm.bridge_all import model_info
    def get_token_num(txt): 
        return len(tokenizer.encode(txt, disallowed_special=()))
    input_token_num = get_token_num(inputs)
    if input_token_num < max_token_limit * 3 / 4:
        # å½“è¾“å…¥éƒ¨åˆ†çš„tokenå æ¯”å°äºé™åˆ¶çš„3/4æ—¶ï¼Œè£å‰ªæ—¶
        # 1. æŠŠinputçš„ä½™é‡ç•™å‡ºæ¥
        max_token_limit = max_token_limit - input_token_num
        # 2. æŠŠè¾“å‡ºç”¨çš„ä½™é‡ç•™å‡ºæ¥
        max_token_limit = max_token_limit - 128
        # 3. å¦‚æœä½™é‡å¤ªå°äº†ï¼Œç›´æ¥æ¸…é™¤å†å²
        if max_token_limit < 128:
            history = []
            return history
    else:
        # å½“è¾“å…¥éƒ¨åˆ†çš„tokenå æ¯” > é™åˆ¶çš„3/4æ—¶ï¼Œç›´æ¥æ¸…é™¤å†å²
        history = []
        return history

    everything = ['']
    everything.extend(history)
    n_token = get_token_num('\n'.join(everything))
    everything_token = [get_token_num(e) for e in everything]

    # æˆªæ–­æ—¶çš„é¢—ç²’åº¦
    delta = max(everything_token) // 16

    while n_token > max_token_limit:
        where = np.argmax(everything_token)
        encoded = tokenizer.encode(everything[where], disallowed_special=())
        clipped_encoded = encoded[:len(encoded)-delta]
        everything[where] = tokenizer.decode(clipped_encoded)[:-1]    # -1 to remove the may-be illegal char
        everything_token[where] = get_token_num(everything[where])
        n_token = get_token_num('\n'.join(everything))

    history = everything[1:]
    return history

"""
========================================================================
ç¬¬ä¸‰éƒ¨åˆ†
å…¶ä»–å°å·¥å…·:
    - zip_folder:    æŠŠæŸä¸ªè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶å‹ç¼©ï¼Œç„¶åè½¬ç§»åˆ°æŒ‡å®šçš„å¦ä¸€ä¸ªè·¯å¾„ä¸­ï¼ˆgptå†™çš„ï¼‰
    - gen_time_str:  ç”Ÿæˆæ—¶é—´æˆ³
    - ProxyNetworkActivate: ä¸´æ—¶åœ°å¯åŠ¨ä»£ç†ç½‘ç»œï¼ˆå¦‚æœæœ‰ï¼‰
    - objdump/objload: å¿«æ·çš„è°ƒè¯•å‡½æ•°
========================================================================
"""

def zip_folder(source_folder, dest_folder, zip_name):
    import zipfile
    import os
    # Make sure the source folder exists
    if not os.path.exists(source_folder):
        print(f"{source_folder} does not exist")
        return

    # Make sure the destination folder exists
    if not os.path.exists(dest_folder):
        print(f"{dest_folder} does not exist")
        return

    # Create the name for the zip file
    zip_file = pj(dest_folder, zip_name)

    # Create a ZipFile object
    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # Walk through the source folder and add files to the zip file
        for foldername, subfolders, filenames in os.walk(source_folder):
            for filename in filenames:
                filepath = pj(foldername, filename)
                zipf.write(filepath, arcname=os.path.relpath(filepath, source_folder))

    # Move the zip file to the destination folder (if it wasn't already there)
    if os.path.dirname(zip_file) != dest_folder:
        os.rename(zip_file, pj(dest_folder, os.path.basename(zip_file)))
        zip_file = pj(dest_folder, os.path.basename(zip_file))

    print(f"Zip file created at {zip_file}")

def zip_result(folder):
    t = gen_time_str()
    zip_folder(folder, get_log_folder(), f'{t}-result.zip')
    return pj(get_log_folder(), f'{t}-result.zip')

def gen_time_str():
    import time
    return time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())

def get_log_folder(user='default', plugin_name='shared'):
    PATH_LOGGING, = get_conf('PATH_LOGGING')
    _dir = pj(PATH_LOGGING, user, plugin_name)
    if not os.path.exists(_dir): os.makedirs(_dir)
    return _dir

class ProxyNetworkActivate():
    """
    è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºTempProxyçš„ç©ºä¸Šä¸‹æ–‡ç®¡ç†å™¨, ç”¨äºç»™ä¸€å°æ®µä»£ç ä¸Šä»£ç†
    """
    def __init__(self, task=None) -> None:
        self.task = task
        if not task:
            # ä¸ç»™å®štask, é‚£ä¹ˆæˆ‘ä»¬é»˜è®¤ä»£ç†ç”Ÿæ•ˆ
            self.valid = True
        else:
            # ç»™å®šäº†task, æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹
            from toolbox import get_conf
            WHEN_TO_USE_PROXY, = get_conf('WHEN_TO_USE_PROXY')
            self.valid = (task in WHEN_TO_USE_PROXY)

    def __enter__(self):
        if not self.valid: return self
        from toolbox import get_conf
        proxies, = get_conf('proxies')
        if 'no_proxy' in os.environ: os.environ.pop('no_proxy')
        if proxies is not None:
            if 'http' in proxies: os.environ['HTTP_PROXY'] = proxies['http']
            if 'https' in proxies: os.environ['HTTPS_PROXY'] = proxies['https']
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        os.environ['no_proxy'] = '*'
        if 'HTTP_PROXY' in os.environ: os.environ.pop('HTTP_PROXY')
        if 'HTTPS_PROXY' in os.environ: os.environ.pop('HTTPS_PROXY')
        return

def objdump(obj, file='objdump.tmp'):
    import pickle
    with open(file, 'wb+') as f:
        pickle.dump(obj, f)
    return

def objload(file='objdump.tmp'):
    import pickle, os
    if not os.path.exists(file): 
        return
    with open(file, 'rb') as f:
        return pickle.load(f)
    
def Singleton(cls):
    """
    ä¸€ä¸ªå•å®ä¾‹è£…é¥°å™¨
    """
    _instance = {}
 
    def _singleton(*args, **kargs):
        if cls not in _instance:
            _instance[cls] = cls(*args, **kargs)
        return _instance[cls]
 
    return _singleton

"""
========================================================================
ç¬¬å››éƒ¨åˆ†
æ¥é©³è™šç©ºç»ˆç«¯:
    - set_conf:                     åœ¨è¿è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€åœ°ä¿®æ”¹é…ç½®
    - set_multi_conf:               åœ¨è¿è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€åœ°ä¿®æ”¹å¤šä¸ªé…ç½®
    - get_plugin_handle:            è·å–æ’ä»¶çš„å¥æŸ„
    - get_plugin_default_kwargs:    è·å–æ’ä»¶çš„é»˜è®¤å‚æ•°
    - get_chat_handle:              è·å–ç®€å•èŠå¤©çš„å¥æŸ„
    - get_chat_default_kwargs:      è·å–ç®€å•èŠå¤©çš„é»˜è®¤å‚æ•°
========================================================================
"""

def set_conf(key, value):
    from toolbox import read_single_conf_with_lru_cache, get_conf
    read_single_conf_with_lru_cache.cache_clear()
    get_conf.cache_clear()
    os.environ[key] = str(value)
    altered, = get_conf(key)
    return altered

def set_multi_conf(dic):
    for k, v in dic.items(): set_conf(k, v)
    return

def get_plugin_handle(plugin_name):
    """
    e.g. plugin_name = 'crazy_functions.æ‰¹é‡Markdownç¿»è¯‘->Markdownç¿»è¯‘æŒ‡å®šè¯­è¨€'
    """
    import importlib
    assert '->' in plugin_name, \
        "Example of plugin_name: crazy_functions.æ‰¹é‡Markdownç¿»è¯‘->Markdownç¿»è¯‘æŒ‡å®šè¯­è¨€"
    module, fn_name = plugin_name.split('->')
    f_hot_reload = getattr(importlib.import_module(module, fn_name), fn_name)
    return f_hot_reload

def get_chat_handle():
    """
    """
    from request_llm.bridge_all import predict_no_ui_long_connection
    return predict_no_ui_long_connection

def get_plugin_default_kwargs():
    """
    """
    from toolbox import get_conf, ChatBotWithCookies

    WEB_PORT, LLM_MODEL, API_KEY = \
        get_conf('WEB_PORT', 'LLM_MODEL', 'API_KEY')

    llm_kwargs = {
        'api_key': API_KEY,
        'llm_model': LLM_MODEL,
        'top_p':1.0, 
        'max_length': None,
        'temperature':1.0,
    }
    chatbot = ChatBotWithCookies(llm_kwargs)

    # txt, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port
    DEFAULT_FN_GROUPS_kwargs = {
        "main_input": "./README.md",
        "llm_kwargs": llm_kwargs,
        "plugin_kwargs": {},
        "chatbot_with_cookie": chatbot,
        "history": [],
        "system_prompt": "You are a good AI.", 
        "web_port": WEB_PORT
    }
    return DEFAULT_FN_GROUPS_kwargs

def get_chat_default_kwargs():
    """
    """
    from toolbox import get_conf

    LLM_MODEL, API_KEY = get_conf('LLM_MODEL', 'API_KEY')

    llm_kwargs = {
        'api_key': API_KEY,
        'llm_model': LLM_MODEL,
        'top_p':1.0, 
        'max_length': None,
        'temperature':1.0,
    }

    default_chat_kwargs = {
        "inputs": "Hello there, are you ready?",
        "llm_kwargs": llm_kwargs,
        "history": [],
        "sys_prompt": "You are AI assistant",
        "observe_window": None,
        "console_slience": False,
    }

    return default_chat_kwargs

